{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYcWEuSw7cph"
      },
      "source": [
        "## MapReduce Introduction\n",
        "\n",
        "The mrjob package is a Python package that simplifies the task of writing MapReduce jobs that can be tested locally and ru non a cluster.  Logic is written in a single class and simplifies the boiler plate to get to the heart of the logic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZMTyJpp7cps",
        "outputId": "05575f61-5e18-4472-b357-87511c45f364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.11/dist-packages (from mrjob) (6.0.2)\n",
            "Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install mrjob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79Xv_Ad87cpv"
      },
      "source": [
        "Here, we grab some text files as an input to our word count programs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt install build-essential libpoppler-cpp-dev pkg-config python3-dev\n",
        "!pip install pdftotext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Y72DCpRisQ8",
        "outputId": "2591b07a-d251-4c14-ef31-362e1dc3e8eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [1 InRelease 3,632 B/3\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [Connected to r2u.stat\r                                                                                                    \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [Connected to r2u.stat\r                                                                                                    \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,381 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,772 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,538 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,041 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,041 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,680 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,238 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,698 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,813 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\n",
            "Fetched 29.7 MB in 4s (7,075 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "python3-dev set to manually installed.\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  libpoppler-cpp0v5\n",
            "The following packages will be REMOVED:\n",
            "  pkgconf r-base-dev\n",
            "The following NEW packages will be installed:\n",
            "  libpoppler-cpp-dev libpoppler-cpp0v5 pkg-config\n",
            "0 upgraded, 3 newly installed, 2 to remove and 35 not upgraded.\n",
            "Need to get 98.7 kB of archives.\n",
            "After this operation, 221 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 pkg-config amd64 0.29.2-1ubuntu3 [48.2 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-cpp0v5 amd64 22.02.0-2ubuntu0.6 [38.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-cpp-dev amd64 22.02.0-2ubuntu0.6 [11.7 kB]\n",
            "Fetched 98.7 kB in 0s (470 kB/s)\n",
            "(Reading database ... 126209 files and directories currently installed.)\n",
            "Removing r-base-dev (4.4.3-1.2204.0) ...\n",
            "\u001b[1mdpkg:\u001b[0m pkgconf: dependency problems, but removing anyway as you requested:\n",
            " libsndfile1-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libopencv-dev depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libmkl-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libjack-dev depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libgphoto2-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libglib2.0-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            " libfontconfig-dev:amd64 depends on pkg-config; however:\n",
            "  Package pkg-config is not installed.\n",
            "  Package pkgconf which provides pkg-config is to be removed.\n",
            "\n",
            "Removing pkgconf (1.8.0-1) ...\n",
            "Removing 'diversion of /usr/bin/pkg-config to /usr/bin/pkg-config.real by pkgconf'\n",
            "Removing 'diversion of /usr/share/aclocal/pkg.m4 to /usr/share/aclocal/pkg.real.m4 by pkgconf'\n",
            "Removing 'diversion of /usr/share/man/man1/pkg-config.1.gz to /usr/share/man/man1/pkg-config.real.1.gz by pkgconf'\n",
            "Removing 'diversion of /usr/share/pkg-config-crosswrapper to /usr/share/pkg-config-crosswrapper.real by pkgconf'\n",
            "Selecting previously unselected package pkg-config.\n",
            "(Reading database ... 126185 files and directories currently installed.)\n",
            "Preparing to unpack .../pkg-config_0.29.2-1ubuntu3_amd64.deb ...\n",
            "Unpacking pkg-config (0.29.2-1ubuntu3) ...\n",
            "Selecting previously unselected package libpoppler-cpp0v5:amd64.\n",
            "Preparing to unpack .../libpoppler-cpp0v5_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking libpoppler-cpp0v5:amd64 (22.02.0-2ubuntu0.6) ...\n",
            "Selecting previously unselected package libpoppler-cpp-dev:amd64.\n",
            "Preparing to unpack .../libpoppler-cpp-dev_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking libpoppler-cpp-dev:amd64 (22.02.0-2ubuntu0.6) ...\n",
            "Setting up pkg-config (0.29.2-1ubuntu3) ...\n",
            "Setting up libpoppler-cpp0v5:amd64 (22.02.0-2ubuntu0.6) ...\n",
            "Setting up libpoppler-cpp-dev:amd64 (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Collecting pdftotext\n",
            "  Downloading pdftotext-3.0.0.tar.gz (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pdftotext\n",
            "  Building wheel for pdftotext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdftotext: filename=pdftotext-3.0.0-cp311-cp311-linux_x86_64.whl size=61776 sha256=e6b33da515725e1c713205759d6410f4757f43a3e032bca177461b382442e2d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/9a/e8/8e4ad1f00ef868e5b2c6f4b1a4664a52796e73967ec5aecd24\n",
            "Successfully built pdftotext\n",
            "Installing collected packages: pdftotext\n",
            "Successfully installed pdftotext-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdftotext\n",
        "!wget https://s21.q4cdn.com/399680738/files/doc_financials/2024/q4/META-Q4-2024-Earnings-Call-Transcript.pdf\n",
        "with open(\"/content/META-Q4-2024-Earnings-Call-Transcript.pdf\", \"rb\") as f:\n",
        "    pdf = pdftotext.PDF(f)\n",
        "\n",
        "# Save all text to a txt file.\n",
        "with open('META.txt', 'w') as f:\n",
        "    f.write(\"\\n\\n\".join(pdf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a34vwz0wiko8",
        "outputId": "ae8110ae-4b76-4e4e-ecce-3e0ab2716f8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-25 23:04:49--  https://s21.q4cdn.com/399680738/files/doc_financials/2024/q4/META-Q4-2024-Earnings-Call-Transcript.pdf\n",
            "Resolving s21.q4cdn.com (s21.q4cdn.com)... 68.70.205.4, 68.70.205.3, 68.70.205.2, ...\n",
            "Connecting to s21.q4cdn.com (s21.q4cdn.com)|68.70.205.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 127873 (125K) [application/pdf]\n",
            "Saving to: ‘META-Q4-2024-Earnings-Call-Transcript.pdf.3’\n",
            "\n",
            "\r          META-Q4-2   0%[                    ]       0  --.-KB/s               \rMETA-Q4-2024-Earnin 100%[===================>] 124.88K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-03-25 23:04:49 (3.82 MB/s) - ‘META-Q4-2024-Earnings-Call-Transcript.pdf.3’ saved [127873/127873]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LY_bCiZ7cpy"
      },
      "source": [
        "### Basic Word Statistics\n",
        "\n",
        "The following MapReduce job takes the input and counts the number of characters, words and lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x7bQW3W7cpy",
        "outputId": "d21f7758-cf95-48c2-da7f-81b4d04057a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting word_stat_count.py\n"
          ]
        }
      ],
      "source": [
        "%%file word_stat_count.py\n",
        "# From http://mrjob.readthedocs.org/en/latest/guides/quickstart.html#writing-your-first-job\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "\n",
        "\n",
        "class MRWordStatCount(MRJob):\n",
        "\n",
        "    # This mapper gets called on each line of the input. In return,\n",
        "    # it will return three different tuples for any given line.\n",
        "    def mapper(self, _, line):\n",
        "        yield \"chars\", len(line)\n",
        "        yield \"words\", len(line.split(\" \"))\n",
        "        yield \"lines\", 1\n",
        "\n",
        "    '''\n",
        "    \"lines\", 1\n",
        "    \"lines\", 1\n",
        "    \"lines\", 1\n",
        "    \"chars\", 30\n",
        "    \"words\", 10\n",
        "    \"chars\", 20\n",
        "    \"words\", 8\n",
        "    \"chars\", 60\n",
        "    \"words\", 20\n",
        "\n",
        "    '''\n",
        "\n",
        "    # All the tuples with the same key (chars, words or lines)\n",
        "    # get passed to the reducer. The reducer aggregates this\n",
        "    # data and returns a single tuple with the key and the sum\n",
        "    # of all the values passed in\n",
        "    def reducer(self, key, values):\n",
        "        yield key, sum(values)\n",
        "\n",
        "    '''\n",
        "    \"lines\", 3\n",
        "    \"chars\", 110\n",
        "    '''\n",
        "\n",
        "# lines below pass control over the command line arguments and execution to mrjob. Without them, your job will not work.\n",
        "if __name__ == '__main__':\n",
        "    MRWordStatCount.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDKCG-aB7cp0",
        "outputId": "4f61a04b-8b48-40f5-a391-9d78e416ffcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for local runner\n",
            "Creating temp directory /tmp/word_stat_count.root.20250325.230647.670520\n",
            "Running step 1 of 1...\n",
            "job output is in word_stat_count_out\n",
            "Removing temp directory /tmp/word_stat_count.root.20250325.230647.670520...\n"
          ]
        }
      ],
      "source": [
        "!python word_stat_count.py -r local *.txt --output-dir=word_stat_count_out --no-output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sLD3E-t7cp1",
        "outputId": "ca783de3-4864-4179-dbb3-362408615628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"chars\"\t52948\n",
            "\"lines\"\t865\n",
            "\"words\"\t9467\n"
          ]
        }
      ],
      "source": [
        "!cat word_stat_count_out/part-0000*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmlpQVaY7cp3"
      },
      "source": [
        "### Word Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfDVNcic7cp5",
        "outputId": "3e75cfa4-ed1c-4d4c-a37d-925a0f74c1cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing word_count.py\n"
          ]
        }
      ],
      "source": [
        "%%file word_count.py\n",
        "# From http://mrjob.readthedocs.org/en/latest/guides/quickstart.html#writing-your-first-job\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "\n",
        "class MRWordCount(MRJob):\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        for word in WORD_RE.findall(line):\n",
        "            yield word.lower(), 1\n",
        "    '''\n",
        "    \"thank\", 1\n",
        "    \"you\", 1\n",
        "    \"good\", 1\n",
        "    \"morning\", 1\n",
        "    \"operator\", 1\n",
        "    \"thank\", 1\n",
        "    '''\n",
        "    # optional combiner job\n",
        "    #def combiner(self, word, counts):\n",
        "    #    yield word, sum(counts)\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        yield key, sum(values)\n",
        "\n",
        "    '''\n",
        "    \"thank\", 2\n",
        "    \"you\", 20\n",
        "    \"good\", 50\n",
        "    \"monring\", 1\n",
        "    \"operator\", 10\n",
        "    '''\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRWordCount.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqigFsis7cp7",
        "outputId": "9f48ed38-5845-48f4-a7d5-0999df3ee0d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for local runner\n",
            "Creating temp directory /tmp/word_count.root.20250325.230734.134832\n",
            "Running step 1 of 1...\n",
            "job output is in word_count_out\n",
            "Removing temp directory /tmp/word_count.root.20250325.230734.134832...\n"
          ]
        }
      ],
      "source": [
        "!python word_count.py -r local *.txt --output-dir=word_count_out --no-output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXsQxZ5U7cp8",
        "outputId": "5d6fe7e4-3fb5-4312-9b9d-264f1ce6c8be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> word_count_out/part-00000 <==\n",
            "\"0\"\t4\n",
            "\"000\"\t1\n",
            "\"000x\"\t1\n",
            "\"02\"\t1\n",
            "\"1\"\t9\n",
            "\"10\"\t5\n",
            "\"100\"\t1\n",
            "\"11\"\t2\n",
            "\"114\"\t1\n",
            "\"119\"\t1\n",
            "\"12\"\t3\n",
            "\"13\"\t3\n",
            "\"14\"\t3\n",
            "\"15\"\t3\n",
            "\"16\"\t2\n",
            "\"17\"\t1\n",
            "\"18\"\t3\n",
            "\"19\"\t2\n",
            "\"1gw\"\t1\n",
            "\"2\"\t2\n",
            "\"20\"\t2\n",
            "\"2024\"\t8\n",
            "\"2025\"\t24\n",
            "\"21\"\t3\n",
            "\"22\"\t1\n",
            "\"23\"\t2\n",
            "\"25\"\t5\n",
            "\"26\"\t2\n",
            "\"27\"\t2\n",
            "\"28\"\t2\n",
            "\"29th\"\t1\n",
            "\"2gw\"\t1\n",
            "\"3\"\t12\n",
            "\"320\"\t1\n",
            "\"39\"\t1\n",
            "\"4\"\t14\n",
            "\"41\"\t1\n",
            "\"46\"\t1\n",
            "\"47\"\t1\n",
            "\"48\"\t3\n",
            "\"5\"\t7\n",
            "\"519\"\t1\n",
            "\"55\"\t1\n",
            "\"55b\"\t1\n",
            "\"6\"\t4\n",
            "\"60\"\t3\n",
            "\"600\"\t1\n",
            "\"65\"\t2\n",
            "\"67\"\t1\n",
            "\"7\"\t1\n",
            "\n",
            "==> word_count_out/part-00001 <==\n",
            "\"each\"\t3\n",
            "\"earlier\"\t2\n",
            "\"early\"\t7\n",
            "\"earnings\"\t4\n",
            "\"easier\"\t2\n",
            "\"easy\"\t2\n",
            "\"ecosystem\"\t1\n",
            "\"editing\"\t1\n",
            "\"edits\"\t1\n",
            "\"educational\"\t1\n",
            "\"effect\"\t4\n",
            "\"effective\"\t4\n",
            "\"effectiveness\"\t1\n",
            "\"efficiencies\"\t2\n",
            "\"efficiency\"\t7\n",
            "\"efficient\"\t4\n",
            "\"efficiently\"\t2\n",
            "\"efforts\"\t4\n",
            "\"either\"\t2\n",
            "\"electronics\"\t1\n",
            "\"emerged\"\t1\n",
            "\"emotional\"\t1\n",
            "\"employee\"\t6\n",
            "\"employees\"\t1\n",
            "\"enable\"\t2\n",
            "\"enabled\"\t1\n",
            "\"enabling\"\t2\n",
            "\"end\"\t5\n",
            "\"ended\"\t2\n",
            "\"ending\"\t1\n",
            "\"energies\"\t1\n",
            "\"engage\"\t3\n",
            "\"engagement\"\t9\n",
            "\"engaging\"\t1\n",
            "\"engineer\"\t3\n",
            "\"engineering\"\t2\n",
            "\"engineers\"\t3\n",
            "\"enhance\"\t1\n",
            "\"enhancements\"\t1\n",
            "\"enjoy\"\t1\n",
            "\"ensure\"\t3\n",
            "\"entering\"\t1\n",
            "\"entertainment\"\t1\n",
            "\"entirely\"\t1\n",
            "\"equipment\"\t2\n",
            "\"eric\"\t2\n",
            "\"especially\"\t1\n",
            "\"establishing\"\t1\n",
            "\"estimate\"\t2\n",
            "\"eu\"\t1\n",
            "\n",
            "==> word_count_out/part-00002 <==\n",
            "\"million\"\t8\n",
            "\"millions\"\t3\n",
            "\"mini\"\t1\n",
            "\"misinformation\"\t2\n",
            "\"mix\"\t4\n",
            "\"model\"\t7\n",
            "\"models\"\t12\n",
            "\"momentum\"\t1\n",
            "\"monetization\"\t12\n",
            "\"monetizing\"\t5\n",
            "\"monitor\"\t1\n",
            "\"month\"\t1\n",
            "\"monthly\"\t5\n",
            "\"months\"\t4\n",
            "\"more\"\t61\n",
            "\"morgan\"\t1\n",
            "\"most\"\t12\n",
            "\"mostly\"\t2\n",
            "\"move\"\t2\n",
            "\"moves\"\t2\n",
            "\"moving\"\t2\n",
            "\"mtia\"\t6\n",
            "\"much\"\t11\n",
            "\"multimodal\"\t1\n",
            "\"multistep\"\t1\n",
            "\"multiyear\"\t1\n",
            "\"mute\"\t1\n",
            "\"my\"\t7\n",
            "\"narrow\"\t1\n",
            "\"national\"\t1\n",
            "\"natively\"\t1\n",
            "\"nature\"\t1\n",
            "\"near\"\t3\n",
            "\"nearly\"\t1\n",
            "\"necessarily\"\t3\n",
            "\"need\"\t5\n",
            "\"needs\"\t7\n",
            "\"net\"\t2\n",
            "\"network\"\t2\n",
            "\"networking\"\t4\n",
            "\"networks\"\t1\n",
            "\"new\"\t20\n",
            "\"news\"\t2\n",
            "\"next\"\t18\n",
            "\"no\"\t2\n",
            "\"non\"\t8\n",
            "\"nonetheless\"\t1\n",
            "\"north\"\t1\n",
            "\"not\"\t13\n",
            "\"note\"\t4\n",
            "\n",
            "==> word_count_out/part-00003 <==\n",
            "\"supporting\"\t2\n",
            "\"sure\"\t5\n",
            "\"surface\"\t1\n",
            "\"surfaces\"\t5\n",
            "\"surpassing\"\t1\n",
            "\"surprises\"\t3\n",
            "\"susan\"\t14\n",
            "\"sustainable\"\t1\n",
            "\"system\"\t8\n",
            "\"systems\"\t6\n",
            "\"t\"\t30\n",
            "\"take\"\t8\n",
            "\"taking\"\t6\n",
            "\"talent\"\t3\n",
            "\"talk\"\t6\n",
            "\"talked\"\t5\n",
            "\"talking\"\t2\n",
            "\"task\"\t2\n",
            "\"tasks\"\t2\n",
            "\"tax\"\t4\n",
            "\"teams\"\t1\n",
            "\"technical\"\t5\n",
            "\"technologies\"\t1\n",
            "\"technology\"\t2\n",
            "\"tell\"\t1\n",
            "\"telling\"\t1\n",
            "\"tens\"\t1\n",
            "\"term\"\t12\n",
            "\"terms\"\t5\n",
            "\"test\"\t3\n",
            "\"tested\"\t1\n",
            "\"testing\"\t1\n",
            "\"than\"\t17\n",
            "\"thank\"\t13\n",
            "\"thanks\"\t9\n",
            "\"that\"\t219\n",
            "\"that's\"\t1\n",
            "\"the\"\t325\n",
            "\"their\"\t20\n",
            "\"them\"\t10\n",
            "\"then\"\t17\n",
            "\"there\"\t22\n",
            "\"there's\"\t1\n",
            "\"these\"\t21\n",
            "\"they\"\t14\n",
            "\"thing\"\t11\n",
            "\"things\"\t15\n",
            "\"think\"\t83\n",
            "\"thinking\"\t7\n",
            "\"third\"\t3\n"
          ]
        }
      ],
      "source": [
        "!head -50 word_count_out/part-0000*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMdeEdp17cp-"
      },
      "source": [
        "### Multi-step Job / Most Frequent Word\n",
        "\n",
        "**SQL equivalent:**\n",
        "```\n",
        "with word_count as (\n",
        "    select\n",
        "       count(*) as count, word\n",
        "    from books\n",
        "    group by\n",
        "       word)\n",
        "\n",
        "select\n",
        "   word, count\n",
        "from word_count\n",
        "order by count desc\n",
        "limit 1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZszqIS6B7cp_",
        "outputId": "8fa9cefb-3e34-4580-e8f0-1820a50fa92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing word_max_count.py\n"
          ]
        }
      ],
      "source": [
        "%%file word_max_count.py\n",
        "# From http://mrjob.readthedocs.org/en/latest/guides/quickstart.html#writing-your-first-job\n",
        "\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import re\n",
        "\n",
        "WORD_RE = re.compile(r\"[\\w']+\")\n",
        "\n",
        "class MRMaxWordCount(MRJob):\n",
        "\n",
        "    # These three functions comprise the first step of the\n",
        "    # MapReduce Job\n",
        "    # Count # of appears by each word\n",
        "    def mapper(self, _, line):\n",
        "        for word in WORD_RE.findall(line):\n",
        "            yield word.lower(), 1\n",
        "    '''\n",
        "    \"thank\", 1\n",
        "    \"you\", 1\n",
        "    \"thank\", 1\n",
        "    .......\n",
        "    '''\n",
        "\n",
        "    def combiner(self, word, counts):\n",
        "        yield word, sum(counts)\n",
        "\n",
        "    '''\n",
        "    \"thank\", 2\n",
        "    \"you\", 1\n",
        "    ......\n",
        "    '''\n",
        "\n",
        "    def reducer(self, word, counts):\n",
        "        yield None, (sum(counts), word)\n",
        "\n",
        "    '''\n",
        "    None, (2, \"thank\")\n",
        "    None, (1, \"you\")\n",
        "    None, (5, \"meta\")\n",
        "    None, (2, \"facebook\")\n",
        "    '''\n",
        "\n",
        "    # This represents the second step of the Job. Here, we are\n",
        "    # only running a reducer (you can think of this as if the\n",
        "    # mapper and combiner return the identity value)\n",
        "    def reducer_max_word(self, _, pairs):\n",
        "        yield max(pairs)\n",
        "\n",
        "    # The steps function defines the sequence of steps\n",
        "    # take the max # of appeared word\n",
        "    def steps(self):\n",
        "        return[\n",
        "            MRStep(\n",
        "                mapper=self.mapper,\n",
        "                combiner=self.combiner,\n",
        "                reducer=self.reducer),\n",
        "            MRStep(\n",
        "                reducer=self.reducer_max_word\n",
        "            )\n",
        "        ]\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRMaxWordCount.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7poWzAMG7cqB",
        "outputId": "ed2f0ab9-5da9-478f-8f77-5c6ed472d535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for local runner\n",
            "Creating temp directory /tmp/word_max_count.root.20250325.230810.995417\n",
            "Running step 1 of 2...\n",
            "Running step 2 of 2...\n",
            "job output is in word_max_count_out\n",
            "Removing temp directory /tmp/word_max_count.root.20250325.230810.995417...\n"
          ]
        }
      ],
      "source": [
        "!python word_max_count.py -r local *.txt --output-dir=word_max_count_out --no-output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhD9A_ZR7cqC",
        "outputId": "d42f5639-8f00-439b-e064-a64cf0289152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "348\t\"to\"\n"
          ]
        }
      ],
      "source": [
        "!cat word_max_count_out/part-0000*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwlsPiXW7cqE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}